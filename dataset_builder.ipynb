{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10: Dataset Frankenstein — budujemy dane do ML\n",
    "\n",
    "W tym notebooku zbudujemy dataset do predykcji defektów.\n",
    "Każdy wiersz to plik `.py`, kolumny to metryki kodu, a ostatnia kolumna mówi czy plik jest \"buggy\" czy \"clean\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importy i konfiguracja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime, date\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from radon.complexity import cc_visit\n",
    "\n",
    "# Konfiguracja wykresów\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Ścieżka do repozytorium do analizy\n",
    "REPO_PATH = \"/tmp/requests\"  # <-- zmień na swoją ścieżkę\n",
    "\n",
    "# Słowa kluczowe do wykrywania commitów naprawiających bugi\n",
    "BUG_KEYWORDS = [\"fix\", \"bug\", \"error\", \"fault\", \"defect\", \"patch\", \"repair\", \"crash\", \"issue\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Zbieranie listy plików .py\n",
    "\n",
    "Znajdźcie wszystkie pliki `.py` w projekcie. Pomińcie katalogi z testami, `setup.py`, `conftest.py` i inne pliki konfiguracyjne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_python_files(repo_path: str) -> list[str]:\n",
    "    \"\"\"Znajdź wszystkie pliki .py w repozytorium (bez testów).\"\"\"\n",
    "    exclude = {\"test\", \"tests\", \"testing\", \"__pycache__\", \".tox\", \".eggs\"}\n",
    "    exclude_files = {\"setup.py\", \"conftest.py\", \"noxfile.py\", \"tasks.py\"}\n",
    "    \n",
    "    py_files = []\n",
    "    for path in Path(repo_path).rglob(\"*.py\"):\n",
    "        # Pomiń katalogi z testami\n",
    "        parts = set(path.relative_to(repo_path).parts)\n",
    "        if parts & exclude:\n",
    "            continue\n",
    "        if path.name in exclude_files:\n",
    "            continue\n",
    "        py_files.append(str(path.relative_to(repo_path)))\n",
    "    \n",
    "    return sorted(py_files)\n",
    "\n",
    "py_files = find_python_files(REPO_PATH)\n",
    "print(f\"Znaleziono {len(py_files)} plików .py\")\n",
    "for f in py_files:\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metryki produktowe: LOC i złożoność cyklomatyczna\n",
    "\n",
    "Dla każdego pliku obliczamy:\n",
    "- **LOC** — liczba niepustych linii\n",
    "- **avg_cc** — średnia złożoność cyklomatyczna (z radon)\n",
    "- **max_cc** — maksymalna CC w pliku\n",
    "- **num_functions** — liczba funkcji/metod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loc(filepath: str) -> int:\n",
    "    \"\"\"Policz niepuste linie kodu (bez komentarzy).\"\"\"\n",
    "    # TODO: Zaimplementuj liczenie LOC\n",
    "    # Wskazówka: otwórz plik, pomiń puste linie i linie z samym komentarzem (#)\n",
    "    pass\n",
    "\n",
    "\n",
    "def compute_complexity(filepath: str) -> dict:\n",
    "    \"\"\"Oblicz metryki złożoności cyklomatycznej z radon.\"\"\"\n",
    "    # TODO: Zaimplementuj obliczanie CC\n",
    "    # Wskazówka: użyj radon.complexity.cc_visit(source_code)\n",
    "    # Zwróć dict z kluczami: avg_cc, max_cc, num_functions\n",
    "    pass\n",
    "\n",
    "\n",
    "# Zbierz metryki produktowe\n",
    "product_metrics = []\n",
    "\n",
    "for pyfile in py_files:\n",
    "    filepath = os.path.join(REPO_PATH, pyfile)\n",
    "    try:\n",
    "        loc = compute_loc(filepath)\n",
    "        cc = compute_complexity(filepath)\n",
    "        product_metrics.append({\n",
    "            \"filename\": pyfile,\n",
    "            \"loc\": loc,\n",
    "            \"avg_cc\": cc[\"avg_cc\"],\n",
    "            \"max_cc\": cc[\"max_cc\"],\n",
    "            \"num_functions\": cc[\"num_functions\"],\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd przy {pyfile}: {e}\")\n",
    "\n",
    "df_product = pd.DataFrame(product_metrics)\n",
    "print(f\"Zebrano metryki produktowe dla {len(df_product)} plików\")\n",
    "df_product.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Metryki procesowe: churn, autorzy, wiek\n",
    "\n",
    "Z `git log --numstat` wyciągamy:\n",
    "- **churn** — suma dodanych i usuniętych linii we wszystkich commitach\n",
    "- **num_commits** — ile razy plik był zmieniany\n",
    "- **num_authors** — ilu różnych autorów dotknęło pliku\n",
    "- **age_days** — ile dni temu plik pojawił się w repozytorium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_git_log(repo_path: str) -> list[dict]:\n",
    "    \"\"\"Parsuj git log --numstat i zwróć listę commitów.\"\"\"\n",
    "    result = subprocess.run(\n",
    "        [\"git\", \"log\", \"--numstat\",\n",
    "         \"--format=%H|%an|%ad|%s\", \"--date=short\"],\n",
    "        cwd=repo_path,\n",
    "        capture_output=True, text=True, check=True,\n",
    "        encoding=\"utf-8\", errors=\"replace\",\n",
    "    )\n",
    "\n",
    "    commits = []\n",
    "    current = None\n",
    "\n",
    "    for line in result.stdout.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if \"|\" in line and len(line.split(\"|\")) >= 4:\n",
    "            if current:\n",
    "                commits.append(current)\n",
    "            parts = line.split(\"|\")\n",
    "            current = {\n",
    "                \"hash\": parts[0],\n",
    "                \"author\": parts[1],\n",
    "                \"date\": parts[2],\n",
    "                \"message\": \"|\".join(parts[3:]),\n",
    "                \"files\": [],\n",
    "            }\n",
    "        elif line and current and \"\\t\" in line:\n",
    "            parts = line.split(\"\\t\")\n",
    "            if len(parts) == 3:\n",
    "                adds = int(parts[0]) if parts[0] != \"-\" else 0\n",
    "                dels = int(parts[1]) if parts[1] != \"-\" else 0\n",
    "                current[\"files\"].append({\n",
    "                    \"path\": parts[2], \"adds\": adds, \"deletes\": dels,\n",
    "                })\n",
    "\n",
    "    if current:\n",
    "        commits.append(current)\n",
    "\n",
    "    return commits\n",
    "\n",
    "commits = parse_git_log(REPO_PATH)\n",
    "print(f\"Sparsowano {len(commits)} commitów\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_process_metrics(commits: list[dict], py_files: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"Oblicz metryki procesowe per plik.\"\"\"\n",
    "    # TODO: Zaimplementuj obliczanie metryk procesowych\n",
    "    # Dla każdego pliku z py_files zbierz:\n",
    "    # - churn (suma adds + deletes ze wszystkich commitów)\n",
    "    # - num_commits (ile commitów dotknęło tego pliku)\n",
    "    # - num_authors (ilu unikatowych autorów)\n",
    "    # - age_days (różnica między dzisiejszą datą a datą najstarszego commitu z tym plikiem)\n",
    "    #\n",
    "    # Wskazówka: iteruj po commitach i ich plikach,\n",
    "    # zbieraj dane w defaultdict, potem zamień na DataFrame\n",
    "    pass\n",
    "\n",
    "df_process = compute_process_metrics(commits, py_files)\n",
    "print(f\"Zebrano metryki procesowe dla {len(df_process)} plików\")\n",
    "df_process.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Etykietowanie: buggy vs clean\n",
    "\n",
    "Plik jest \"buggy\" jeśli był zmieniany w commicie z wiadomością zawierającą słowa kluczowe sugerujące naprawę błędu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_buggy_files(commits: list[dict], py_files: list[str]) -> dict[str, int]:\n",
    "    \"\"\"Oznacz pliki jako buggy (1) lub clean (0).\"\"\"\n",
    "    # TODO: Zaimplementuj etykietowanie\n",
    "    # Dla każdego commitu sprawdź czy wiadomość zawiera BUG_KEYWORDS\n",
    "    # Jeśli tak, oznacz wszystkie pliki .py z tego commitu jako buggy\n",
    "    # Zwróć dict: filename -> 1 (buggy) lub 0 (clean)\n",
    "    pass\n",
    "\n",
    "labels = label_buggy_files(commits, py_files)\n",
    "buggy_count = sum(labels.values())\n",
    "clean_count = len(labels) - buggy_count\n",
    "print(f\"Buggy: {buggy_count}, Clean: {clean_count}\")\n",
    "print(f\"Stosunek buggy: {buggy_count / len(labels) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Złączenie w jeden dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Złącz metryki produktowe i procesowe\n",
    "df = df_product.merge(df_process, on=\"filename\", how=\"inner\")\n",
    "\n",
    "# Dodaj etykiety\n",
    "df[\"is_buggy\"] = df[\"filename\"].map(labels).fillna(0).astype(int)\n",
    "\n",
    "print(f\"Finalny dataset: {len(df)} wierszy, {len(df.columns)} kolumn\")\n",
    "print(f\"\\nKolumny: {list(df.columns)}\")\n",
    "print(f\"\\nBuggy: {df['is_buggy'].sum()}, Clean: {(df['is_buggy'] == 0).sum()}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisz dataset\n",
    "df.to_csv(\"dataset.csv\", index=False)\n",
    "print(\"Zapisano dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Eksploracja danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Statystyki opisowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Rozkłady cech (histogramy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"loc\", \"avg_cc\", \"max_cc\", \"churn\", \"num_commits\", \"num_authors\", \"age_days\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(features):\n",
    "    axes[i].hist(df[feat], bins=20, edgecolor=\"black\", alpha=0.7)\n",
    "    axes[i].set_title(feat)\n",
    "    axes[i].set_ylabel(\"Liczba plików\")\n",
    "\n",
    "# Ukryj ostatni pusty wykres\n",
    "axes[-1].set_visible(False)\n",
    "\n",
    "plt.suptitle(\"Rozkłady cech\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Balans klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Wykres kołowy\n",
    "counts = df[\"is_buggy\"].value_counts()\n",
    "ax1.pie(counts, labels=[\"Clean\", \"Buggy\"], autopct=\"%1.1f%%\",\n",
    "        colors=[\"#2ecc71\", \"#e74c3c\"])\n",
    "ax1.set_title(\"Balans klas\")\n",
    "\n",
    "# Wykres słupkowy\n",
    "counts.plot(kind=\"bar\", ax=ax2, color=[\"#2ecc71\", \"#e74c3c\"])\n",
    "ax2.set_title(\"Liczba plików per klasa\")\n",
    "ax2.set_xticklabels([\"Clean (0)\", \"Buggy (1)\"], rotation=0)\n",
    "ax2.set_ylabel(\"Liczba plików\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Macierz korelacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "corr = df[features + [\"is_buggy\"]].corr()\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"RdBu_r\",\n",
    "            center=0, vmin=-1, vmax=1)\n",
    "plt.title(\"Macierz korelacji\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Boxploty: buggy vs clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(features):\n",
    "    sns.boxplot(data=df, x=\"is_buggy\", y=feat, ax=axes[i],\n",
    "                palette=[\"#2ecc71\", \"#e74c3c\"])\n",
    "    axes[i].set_title(feat)\n",
    "    axes[i].set_xticklabels([\"Clean\", \"Buggy\"])\n",
    "\n",
    "axes[-1].set_visible(False)\n",
    "\n",
    "plt.suptitle(\"Porównanie cech: Buggy vs Clean\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Odpowiedzi na pytania\n",
    "\n",
    "Odpowiedzcie na poniższe pytania (zamieńcie TODO na odpowiedzi):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Ile plików .py znaleźliście? Ile z nich jest buggy, a ile clean?**\n",
    "\n",
    "TODO: Twoja odpowiedź"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Czy dataset jest zbalansowany? Jaki jest stosunek buggy:clean?**\n",
    "\n",
    "TODO: Twoja odpowiedź"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Które cechy najbardziej różnią się między buggy a clean?**\n",
    "\n",
    "TODO: Twoja odpowiedź (patrz boxploty powyżej)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Czy widzicie korelacje między cechami? Które cechy są ze sobą skorelowane?**\n",
    "\n",
    "TODO: Twoja odpowiedź (patrz macierz korelacji)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Czy heurystyka etykietowania jest idealna? Jakie są jej wady?**\n",
    "\n",
    "TODO: Twoja odpowiedź"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
